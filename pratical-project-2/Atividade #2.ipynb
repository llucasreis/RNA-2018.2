{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste 2 - 11/09/2018\n",
    "\n",
    "## Disponibilização: 10/09/2018 - 11h\n",
    "## Encerramento: 11/09/2018 - 20h\n",
    "\n",
    "O objetivo deste segundo projeto prático da disciplina Redes Neurais Artificias é praticar os conceitos de Machine Learning vistos até o momento, em especial aqueles relativos ao processo de Aprendizagem de Máquina.\n",
    "\n",
    "Vamos trabalhar com o dataset **Breast Cancer Wisconsin (Diagnostic) Data Set**, vide: <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\">Repositório UCI</a>\n",
    "\n",
    "Esta tarefa é dividida em to-dos, isto é, pequenas atividades que devem ser cumpridas para que o objetivo geral seja alcançado. A cada to-do está associada uma célula do Jupyter Notebook, que deve ser preenchida com código Python atendendo ao que se pede.\n",
    "\n",
    "\n",
    "Edite aqui os nomes dos integrantes da equipe:\n",
    "\n",
    "- Felipe Getúlio Laranjeira do Nascimento\n",
    "- Lucas Pereira Reis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 1\n",
    "\n",
    "1. Você deve importar o dataset a partir do sci-kit learn.\n",
    "Consulte o link: [Link da documentação do sci-kit learn](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
    "   * Este dataset está organizado sob a forma de um dicionário, em que os dados preditores encontram-se na chave 'data', composta de diversas matrizes. Cada matriz está associada a um nome 'feature_names'. \n",
    "2. Crie um novo dicionário que mapeia cada 'feature_name' para uma matriz correspondente.\n",
    "    * Antes de fazer esta associação, transponha a matriz localizada na chave 'data' para obter a dimensão correta.\n",
    "3. Transforme o dataset em um objetivo tipo DataFrame do pandas\n",
    "4. Adicione o atributo-alvo ao dataset existente.\n",
    "    * Importante: O atributo-alvo está na chave 'target' do dicionário, com nome 'target_names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension   ...    worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871   ...            17.33           184.60      2019.0   \n",
       "1                 0.05667   ...            23.41           158.80      1956.0   \n",
       "2                 0.05999   ...            25.53           152.50      1709.0   \n",
       "3                 0.09744   ...            26.50            98.87       567.7   \n",
       "4                 0.05883   ...            16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 2\n",
    "\n",
    "Utilizando `pandas.DataFrame` para manipular o dataset, faça o que se pede:\n",
    "1. Informe a quantidade de exemplos existentes no dataset\n",
    "2. Enumere os atributos existentes no dataset\n",
    "3. Identifique o atributo-alvo e imprima-o\n",
    "4. O dataset é balanceado?\n",
    "5. Remova todos os atributos que contenham a palavra `error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'area error',\n",
       " 'compactness error',\n",
       " 'concave points error',\n",
       " 'concavity error',\n",
       " 'fractal dimension error',\n",
       " 'mean area',\n",
       " 'mean compactness',\n",
       " 'mean concave points',\n",
       " 'mean concavity',\n",
       " 'mean fractal dimension',\n",
       " 'mean perimeter',\n",
       " 'mean radius',\n",
       " 'mean smoothness',\n",
       " 'mean symmetry',\n",
       " 'mean texture',\n",
       " 'perimeter error',\n",
       " 'radius error',\n",
       " 'smoothness error',\n",
       " 'symmetry error',\n",
       " 'texture error',\n",
       " 'worst area',\n",
       " 'worst compactness',\n",
       " 'worst concave points',\n",
       " 'worst concavity',\n",
       " 'worst fractal dimension',\n",
       " 'worst perimeter',\n",
       " 'worst radius',\n",
       " 'worst smoothness',\n",
       " 'worst symmetry',\n",
       " 'worst texture'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     1\n",
       "20     1\n",
       "21     1\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "539    1\n",
       "540    1\n",
       "541    1\n",
       "542    1\n",
       "543    1\n",
       "544    1\n",
       "545    1\n",
       "546    1\n",
       "547    1\n",
       "548    1\n",
       "549    1\n",
       "550    1\n",
       "551    1\n",
       "552    1\n",
       "553    1\n",
       "554    1\n",
       "555    1\n",
       "556    1\n",
       "557    1\n",
       "558    1\n",
       "559    1\n",
       "560    1\n",
       "561    1\n",
       "562    0\n",
       "563    0\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Name: target, Length: 569, dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de exemplos: 569\n",
      "Percentual para cada atributo-alvo\n",
      "Exemplos 0: 0.37258347978910367\n",
      "Exemplos 1: 0.6274165202108963\n",
      "Diferença absoluta: 0.25483304042179267\n"
     ]
    }
   ],
   "source": [
    "print(f'Quantidade de exemplos: {len(df)}')\n",
    "percent0 = df.target[df.target == 0].count() / len(df.target)\n",
    "percent1 = df.target[df.target == 1].count() / len(df.target)\n",
    "print('Percentual para cada atributo-alvo')\n",
    "print(f'Exemplos 0: {percent0}')\n",
    "print(f'Exemplos 1: {percent1}')\n",
    "print(f'Diferença absoluta: {abs(percent0 - percent1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta**: Como existem mais amostras para cânceres positivos do que para negativos e a diferença entre estes excede 5% do total de exemplos, pode-se concluir que o *dataset* não é balanceado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 3\n",
    "\n",
    "Faça uma partição randomizada do tipo 70/30 para conjunto de treinamento e de testes.\n",
    "Em ambos os conjuntos, separe o atributo-alvo.\n",
    "\n",
    "Para facilitar, siga a nomenclatura sugerida:\n",
    "* X_train: atributos preditores para o conjunto de treinamento\n",
    "* X_test: atributos preditores para o conjunto de testes\n",
    "* Y_train: atributo-alvo para os exemplos do conjunto de treinamento\n",
    "* Y_test: atributo-alvo para os exemplos do conjunto de testes\n",
    "\n",
    "Sugestão: [consultar a documentação do sci-kit learn](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.target\n",
    "df.drop(['target'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df,target,test_size=0.3,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 4\n",
    "\n",
    "Vamos usar os dados X_train e Y_train para treinar dois modelos diferentes de Aprendizagem de Máquina.\n",
    "1. Modelo 1: Vizinhos mais próximos, com k = 5\n",
    "2. Modelo 2: Centróides mais próximos, de acordo com a distância Euclidiana\n",
    "\n",
    "Basta completar o código a seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestCentroid(metric='euclidean', shrink_threshold=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "\n",
    "# 5 - vizinhos mais próximos\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train,Y_train)\n",
    "\n",
    "# Kernel Density\n",
    "nc = NearestCentroid()\n",
    "nc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 5\n",
    "\n",
    "Utilizar o conjunto de testes para prever o conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsaokNN = knn.predict(X_test)\n",
    "previsaonc = nc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 6\n",
    "\n",
    "Analisando as diferenças e igualdades entre os vetores previsaokNN, previsaonc e Y_test, construa as matrizes de confusão dos respectivos modelos de Machine Learning. \n",
    "\n",
    "Consulte: [Documentação do sklearn para Matrizes de Confusão](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 52   5]\n",
      " [  5 109]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(Y_test, previsaokNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 43  14]\n",
      " [  2 112]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(Y_test, previsaonc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 7\n",
    "\n",
    "Para cada um dos modelos, apresente:\n",
    "\n",
    "1. Acurácia\n",
    "2. Precisão\n",
    "3. Revocação\n",
    "4. F-Score (Leve em consideração se o dataset é balanceado ou não)\n",
    "\n",
    "Consulte: [Documentação do sklearn para Métricas de Desempenho](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9415204678362573\n",
      "0.9064327485380117\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(Y_test, previsaokNN))\n",
    "print(metrics.accuracy_score(Y_test, previsaonc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9415204678362573\n",
      "0.9064327485380117\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(Y_test, previsaokNN, average='micro'))\n",
    "print(metrics.precision_score(Y_test, previsaonc, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9415204678362573\n",
      "0.9064327485380117\n"
     ]
    }
   ],
   "source": [
    "print(metrics.recall_score(Y_test, previsaokNN, average='micro'))\n",
    "print(metrics.recall_score(Y_test, previsaonc,average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9415204678362573\n",
      "0.9064327485380118\n"
     ]
    }
   ],
   "source": [
    "print(metrics.f1_score(Y_test, previsaokNN, average='micro'))\n",
    "print(metrics.f1_score(Y_test, previsaonc, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do 8\n",
    "\n",
    "Utilizando argumentos textuais, justifique qual dos modelos apresentados é melhor para o problema em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta**: Analisando a matriz de confusão de cada modelo, podemos observar que o modelo 2 apresentou mais valores na diagonal secundária, ou seja, classificou mais amostras erradas do que o modelo 1. Este resultado é reletido nas métricas de desempenho, todas as quatro métricas apresentaram um valor maior para o modelo 1, assim concluiu-se que utilizar vizinhos mais próximos é mais adequado para este problema do que centróides mais próximos. Além disto, estes modelos então prevendo um tipo de diagnóstico clínico, o que é mais refletido no F1-Score, pois este leva em consideração a revocação como métrica, a qual identifica exemplos falsos-negativos, que são de grande peso para previsão de laudos médicos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
